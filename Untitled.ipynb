{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a374192-26d3-44d6-8dba-756b3dc0a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scripts.transformer.modeling import TinyBertForSequenceClassification\n",
    "from scripts.transformer.tokenization import BertTokenizer\n",
    "from scripts.transformer.optimization import BertAdam\n",
    "from scripts.transformer.file_utils import WEIGHTS_NAME, CONFIG_NAME\n",
    "\n",
    "from scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d80b0e0-2288-4998-87aa-f00dbe7a911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "teacher = TinyBertForSequenceClassification.from_pretrained(os.path.join('artifacts', 'BERT-title-content-benchmark:v0'), num_labels = 1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a5a8941-d59a-41fa-98a1-d68de87011b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token length: 512 Batch size: 16 Shuffle: False Title only: False\n"
     ]
    }
   ],
   "source": [
    "# Initialize test data set\n",
    "test_data_loader = create_reliable_news_dataloader(\n",
    "    os.path.join('data','nela_gt_2018_site_split', 'test.jsonl'),\n",
    "    tokenizer,\n",
    "    max_len = 512,\n",
    "    batch_size = 8 * max(1,n_gpu),\n",
    "    sample = False,\n",
    "    title_only = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "471bb9b1-aa17-464e-bd18-43920588945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f2f4d6a16c4b18948e70524156cfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "teacher.to(device)\n",
    "# teacher = torch.nn.DataParallel(teacher)\n",
    "teacher.eval()\n",
    "correct_predictions = 0\n",
    "n_examples = 0\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_data_loader)\n",
    "    for idx, batch in enumerate(loop):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch[\"labels\"].to(device).unsqueeze(1)\n",
    "        \n",
    "        logits, _, _ = teacher(input_ids = input_ids,\n",
    "                                attention_mask = attention_mask,\n",
    "                                token_type_ids = token_type_ids,\n",
    "                                labels = labels)\n",
    "        preds = torch.round(logits)\n",
    "\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        n_examples += len(labels)\n",
    "        \n",
    "        loop.set_postfix(val_acc = float(correct_predictions/n_examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea50c6ea-f732-4944-82d2-e7c4935cc3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer, model = create_model('bert-base-cased', 0.1, False)\n",
    "checkpoint = torch.load(os.path.join('artifacts', 'BERT-title-content-benchmark:v0','pytorch_model.bin'))\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dd5bd2a-12b4-4f12-9273-38e75094d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df8852b6-671d-4bf1-befe-02fbb542fb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcc0cbdf17d41b183b90e7b1fcb2166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct_predictions = 0\n",
    "n_examples = 0\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_data_loader)\n",
    "    for idx, batch in enumerate(loop):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch[\"labels\"].to(device).unsqueeze(1)\n",
    "        \n",
    "        outputs = model(input_ids = input_ids,\n",
    "                        attention_mask = attention_mask,\n",
    "                        token_type_ids = token_type_ids,\n",
    "                        labels = labels)\n",
    "        preds = torch.round(outputs['logits'])\n",
    "\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        n_examples += len(labels)\n",
    "        \n",
    "        loop.set_postfix(val_acc = float(correct_predictions/n_examples))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
